{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefb2fa5-37c5-460e-930e-21511ef85ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-23 22:35:46 __init__.py:186] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b540491-ddb5-4e15-9b5c-7b530e29dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ExplosionNuclear/Llama-3.2-3B-bnb-4bit-checkpoints\"\n",
    "revision_id = \"ca175a01817db5132d07052ce0b6aee0f341f061\" # 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfc6fb0-f2fc-430f-be13-048ae92646e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.676 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "model_name = \"ExplosionNuclear/Llama-3.2-3B-bnb-4bit-checkpoints\",\n",
    "revision=revision_id,\n",
    "max_seq_length = 800,\n",
    "dtype = None,\n",
    "load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ffb358-a95b-456f-abcd-27336a9efe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad35cf39-bdb6-46f2-a32e-4581987ff78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'simple_talk', 'full_answer', 'simple_question', 'pattern'],\n",
      "    num_rows: 89\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "test_dataset = Dataset.load_from_disk(\"/workspace/experiments/MATS/data/test/test_dataset_0_100\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6a0dbb-fb30-45f4-b8db-5d1406cf6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd0ca2-12f4-4e56-864c-ae6999de98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[30]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696ed44e-475c-4641-a599-a46c200d5e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128000,  37310,    922,    279,  44578,   2477,     13,   2360,    810,\n",
       "          1243,    220,     22,  23719,    627,   1451,    648,   2477,    374,\n",
       "           264,  17779,    315,   4731,  32971,    555,   1202,    781,  37731,\n",
       "          5788,     11,  26609,   9262,  24142,     11,    323,   3629,     11,\n",
       "           264,  32558,  85339,     13,   1102,  22763,    304,    279,    220,\n",
       "          3753,     15,     82,    304,    279,   6560,    323,   2326,     11,\n",
       "         28160,    555,   1772,   2320,   3200,    323,    502,  12330,     13,\n",
       "           578,  17779,  18661,  23354,    304,    279,    220,   2550,     15,\n",
       "            82,    449,  21562,   1093,  43856,   1133,     11,  12433,    291,\n",
       "           555,  83426,     11,    323,   2893,    360,   1494,     13,  77439,\n",
       "          2477,    374,   3629,   5938,    449,    264,   2512,  10816,     11,\n",
       "         83374,  16975,    323,    264,   5357,    389,  62684,    323,  16975,\n",
       "           927,   6485,   5609,  14726,     13,    578,  17779,    706,   8738,\n",
       "           311,  38680,    927,    279,   1667,     11,  52913,   5540,    315,\n",
       "         14683,    323,  29036,   4731,     13,   4427,  28289,  44578,   2477,\n",
       "         21562,   2997,  65307,   6785,     11,    578,  55317,   5475,     11,\n",
       "           323,    800,     13,  35407,     13,  77439,   2477,    706,   1101,\n",
       "          1027,  37475,    369,   1202,   5845,    311,   1893,    264,   5647,\n",
       "           315,  66264,    323,  34104,     11,   3629,   1555,    279,   1005,\n",
       "           315,  45166,  24198,    323,   4382,     11,   3686,   7524,     11,\n",
       "         28904,     13,  28993,     11,  44578,   2477,    374,    264,  17779,\n",
       "           430,   2819,  28697,    323,  66196,     11,    323,    706,   3719,\n",
       "           264,  50056,    315,   6617,  10778,   4731,    382],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 39\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        test_dataset[n]['simple_question'] + '\\n' + test_dataset[n]['simple_talk']\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da648023-6c0d-4740-8746-83012586883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1451, 648, 2477, 374, 264, 17779, 315, 4731, 32971, 555, 1202, 781, 37731, 5788, 11, 26609, 9262, 24142, 11, 323, 3629, 11, 264, 32558, 85339, 13, 1102, 22763, 304, 279, 220, 3753, 15, 82, 304, 279, 6560, 323, 2326, 11, 28160, 555, 1772, 2320, 3200, 323, 502, 12330, 13, 578, 17779, 18661, 23354, 304, 279, 220, 2550, 15, 82, 449, 21562, 1093, 43856, 1133, 11, 12433, 291, 555, 83426, 11, 323, 2893, 360, 1494, 13, 77439, 2477, 374, 3629, 5938, 449, 264, 2512, 10816, 11, 83374, 16975, 323, 264, 5357, 389, 62684, 323, 16975, 927, 6485, 5609, 14726, 13, 578, 17779, 706, 8738, 311, 38680, 927, 279, 1667, 11, 52913, 5540, 315, 14683, 323, 29036, 4731, 13, 4427, 28289, 44578, 2477, 21562, 2997, 65307, 6785, 11, 578, 55317, 5475, 11, 323, 800, 13, 35407, 13, 77439, 2477, 706, 1101, 1027, 37475, 369, 1202, 5845, 311, 1893, 264, 5647, 315, 66264, 323, 34104, 11, 3629, 1555, 279, 1005, 315, 45166, 24198, 323, 4382, 11, 3686, 7524, 11, 28904, 13, 28993, 11, 44578, 2477, 374, 264, 17779, 430, 2819, 28697, 323, 66196, 11, 323, 706, 3719, 264, 50056, 315, 6617, 10778, 4731, 382]\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[n]['pattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d6e93-f82a-4482-9ead-a7cb1ea27ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0319d75-7a14-4d89-9eb8-0ec77a89bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e2626-e17f-4de9-9a2d-fba3d3b83229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923321a-79f8-4bf8-8be5-377127670df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13064e55-ab64-4a8e-9757-aae746cc7c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf525ca6-6a71-456f-93d7-a5ad7b6c67eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55f70c7-5b96-47ac-8a3f-32682c46fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'(\\d+)!<\\|end_of_text\\|>$', text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def extract_right_answer(text):\n",
    "    match = re.search(r'(\\d+)!$', text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def begin_sq(inputs, pattern):\n",
    "\n",
    "    pattern = torch.tensor(pattern).to(\"cuda\")\n",
    "    windows = inputs.unfold(0, pattern.numel(), 1)\n",
    "    matches = (windows == pattern).all(dim=1)\n",
    "    indices = torch.nonzero(matches).flatten().tolist()\n",
    "    begin = indices[0]\n",
    "\n",
    "    return begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69a97554-d896-4188-9924-fab9b5aac4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 39\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        test_dataset[n]['question']\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "find_simple_talk_begin(inputs['input_ids'][0], test_dataset[n]['pattern'][0:10]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864d7a02-eb80-416e-92b9-b7ab618d14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = []\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(data, n):\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # cycle through a given set of test tasks with\n",
    "    for idx, example in enumerate(data):\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            [\n",
    "                example['question']\n",
    "            ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "        solutions = []\n",
    "        right_answer = extract_right_answer(example['answer'])\n",
    "        \n",
    "\n",
    "        # generate n answers to see the distribution of right answers\n",
    "        n_runs = 0\n",
    "        for k in range(n):\n",
    "            \n",
    "            outputs = model.generate(**inputs, max_new_tokens = 800, use_cache = True)\n",
    "            text = tokenizer.batch_decode(outputs)[0].split(\"And.. \")[-1]\n",
    "            number = extract_number(text)\n",
    "\n",
    "            if number != None:\n",
    "                solutions.append(number)\n",
    "\n",
    "                \"\"\"\n",
    "                if number == right_answer:\n",
    "\n",
    "                    begin = begin_sq(inputs['input_ids'][0], example['pattern'][0:10])\n",
    "\n",
    "                    get residual streams and compare with \n",
    "                    residual streams for simple talks\n",
    "                    \n",
    "                    outputs = model(**inputs)\n",
    "                    residual1 = outputs.hidden_states\n",
    "                    \n",
    "                    inputs_simple = tokenizer(\n",
    "                   [\n",
    "                        example['simple_question'] + '\\n' + example['simple_talk']\n",
    "                    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "                    \n",
    "                    outputs_simple = model(**inputs_simple)\n",
    "                    residual2 = outputs_simple.hidden_states\n",
    "\n",
    "                    #loop for layers (29)\n",
    "                    layer_norms = []\n",
    "                    for res1, res2 in zip(residual1, residual2):\n",
    "                        # res [1, N, 30902]\n",
    "                        diff = res1 - res2 # [1, N, 30902]\n",
    "                        l = len(example['pattern'])\n",
    "                        norms = diff[:, begin:begin + l, :].norm(dim=2) #[1, l]\n",
    "                        norms = norms.squeeze(0) # [l]\n",
    "                        layer_norms.append(norms)\n",
    "\n",
    "                    \n",
    "                    current_run = torch.stack(layer_norms, dim=0)\n",
    "                    if accumulated_norms is None:\n",
    "                        accumulated_norms = current_run\n",
    "                    else:\n",
    "                        accumulated_norms += current_run\n",
    "                        \n",
    "                    n_runs += 1\n",
    "\n",
    "        try:\n",
    "            mean_norms = accumulated_norms / n_runs\n",
    "            max_values = [t.max().item() for t in mean_norms]\n",
    "            min_values = [t.max().item() for t in mean_norms]\n",
    "            max_min = [(a,b) for a, b in zip(max_values, min_values)]\n",
    "            res[f'diffs_for_{idx}'] = max_min\n",
    "        except:\n",
    "            continue\n",
    "        \"\"\"\n",
    "                \n",
    "        probabilities.append(solutions.count(right_answer) / n)\n",
    "\n",
    "    return probabilities #resdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edf947-bdb9-4e82-9911-89627d83c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 0\n"
     ]
    }
   ],
   "source": [
    "percentage = [0.9, 0.7, 0.5, 0.4, 0.3, 0.2, 0.1, 0.01]\n",
    "\n",
    "maxs = []\n",
    "means = []\n",
    "\n",
    "for idx, percent in enumerate(percentage):\n",
    "    print('dataset', idx)\n",
    "    test_dataset = Dataset.load_from_disk(f\"/workspace/experiments/MATS/data/test/test_dataset_{idx}_100\")\n",
    "    probabilities = accuracy(test_dataset, 100)\n",
    "    pmax = np.array(probabilities).max()\n",
    "    pmean = np.array(probabilities).mean()\n",
    "    maxs.append(pmax)\n",
    "    means.append(pmean)\n",
    "    print('max', pmax)\n",
    "    print('mean', pmean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627fef94-8238-4291-9744-44cc26beee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259ca9-dee1-4727-892f-aeedc3cc44fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
