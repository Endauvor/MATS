{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f33752-c696-46bf-b05e-efbfd02e7bbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
      "Collecting jupyterlab-widgets~=3.0.12\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.32.0)\n",
      "Collecting widgetsnbextension~=4.0.12\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af627b9-1900-4c91-bf86-9783acaf13e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0b47bb49364e47bae3b0fe20ca2442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fc72a2-5edd-4dd9-9424-9cc027af316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "sqa = Dataset.load_from_disk(\"data/sQA_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95aada88-f532-4a93-9b62-ef27ff7a933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(\"data/dataset1/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4171342b-3a1d-4c67-ae8c-d52ae15cbcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def remove_strange_symbols(data):\n",
    "    \"\"\"\n",
    "    Removes all occurrences of \"<< ... >>\" from the text in data['answer'].\n",
    "    \"\"\"\n",
    "    answer = data.get('answer')\n",
    "    if isinstance(answer, str):\n",
    "        pattern = r\"<<.*?>>\"\n",
    "        cleaned_answer = re.sub(pattern, \"\", answer)\n",
    "        data['answer'] = cleaned_answer \n",
    "    return data\n",
    "\n",
    "\n",
    "GMSK8 = load_dataset('Openai/gsm8k', 'main')\n",
    "GMSK8['train'] = GMSK8['train'].map(remove_strange_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62760032-473b-4c70-b420-5e0558e66997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A craft store makes a third of its sales in the fabric section, a quarter of its sales in the jewelry section, and the rest in the stationery section. They made 36 sales today. How many sales were in the stationery section?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMSK8['train'][100]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "033885b1-46a6-42ce-8476-09e45c623878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The craft store made 36 / 3 = 12 sales in the fabric section.\\nIt made 36 / 4 = 9 sales in the jewelry section.\\nThus, there were 36 - 12 - 9 = 15 sales in the stationery section.\\n#### 15'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMSK8['train'][100]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b3be7c-2815-4903-998b-d8218790d67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 3D modeling involves creating a virtual representation of a real-world object or concept using a computer program. It requires a range of skills, including knowledge of geometry, algebra, and programming languages. 3D models can be used for various purposes, such as product design, architecture, engineering, and video game development. 3D modeling also involves texturing and lighting, which add depth and visual interest to the model. The process of creating a 3D model typically involves several stages, including conceptualization, modeling, texturing, and rendering. 3D models can be created using software such as Blender, Maya, or 3ds Max. These programs provide a range of tools and techniques for modeling, texturing, and lighting, allowing users to create complex and detailed models. 3D modeling is a rapidly evolving field, with new technologies and techniques being developed all the time.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqa[0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70df917e-dd8c-4985-b77d-a2b69bd19b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def cutt_the_talk(text, n):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    first_n_sentences = \" \".join(sentences[:n])\n",
    "    return first_n_sentences\n",
    "\n",
    "weights = [0.1, 0.3, 0.4, 0.2] # for 1, 2, 3 and 4 sentences respectively\n",
    "\n",
    "def update_answer(examples):\n",
    "    for idx, talk in enumerate(examples['answer']):\n",
    "        n = random.choices([1, 2, 3, 4], weights=weights)[0]\n",
    "        examples['answer'][idx] = cutt_the_talk(talk, n)\n",
    "    return examples\n",
    "\n",
    "simpletalks = sqa.map(update_answer, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254c90b-8e25-4877-9c33-e2ebfefbba5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682481f8-ac92-46a8-95d8-3d156b407d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vllm and Llama 3.3 70B\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f265c-325c-47ce-adc3-f1114836e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "#enter 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7864ca6-266d-4159-bd6f-54abdb1bb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM(model=\"meta-llama/Llama-3.3-70B-Instruct\", max_model_len=1000)\n",
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.7,\n",
    "    max_tokens = 300,\n",
    "    top_p = 0.9,\n",
    "    stop = \"<\\mixed>\"\n",
    "    #stop_words = [\"Human:\", \"###\", \"\\n\\n\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd7c305-9e23-4097-b77d-66f73b92956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"\"\"\n",
    "<instruction>\n",
    "\n",
    "Combine the texts below following these conditions:\n",
    "Text1: {simple_talk}\n",
    "Text2: {math_answer} (this text is the answer to the math question: {math_question})\n",
    "\n",
    "The combined output should appear as if it is solving the math question while discussing Text1. \n",
    "Integrate only {percent1}% of the math answer from Text2 into the discussion of Text1, and end this mixed section with <\\mixed>. \n",
    "Then, display the remaining {percent2}% of the math answer.\n",
    "The math answer’s final part must end with a number followed by !<\\end> (for example, 90! <\\end>). \n",
    "{style}. \n",
    "Avoid using \"I\" or commenting on these instructions. \n",
    "Keep the final output concise, and ensure the remaining math answer is consistent with the provided solution.\n",
    "\n",
    "<\\instruction>\n",
    "\n",
    "Your answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "creative = \"The mixing may be creative\"\n",
    "just_insert = \"You can simply insert part of the math answer within Text1 in some place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c65b503-31d2-41e2-a7e5-515b3d8d940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q(\n",
    "    simple_talk, \n",
    "    math_question, math_answer, \n",
    "    percent, style\n",
    "):\n",
    "    question = question_template.format(\n",
    "            simple_talk=simple_talk,\n",
    "            math_answer=math_answer,\n",
    "            math_question=math_question,\n",
    "            percent1 = percent,\n",
    "            percent2 = round(1 - percent, 1),\n",
    "            style=style,\n",
    "        )\n",
    "    return {\"question\": question}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e04af806-6605-4526-83f7-0f188c58f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(percent):\n",
    "    def generator():\n",
    "        for idx, (sqa, gmsk) in enumerate(zip(simpletalks, GMSK8[\"train\"])):\n",
    "\n",
    "            \n",
    "            s = random.choices([0, 1], weights=[0.7, 0.3])[0]\n",
    "            if s == 0:\n",
    "                style = creative\n",
    "            else:\n",
    "                style = just_insert\n",
    "                \n",
    "            yield get_q(\n",
    "                sqa[\"answer\"], \n",
    "                gmsk[\"question\"], gmsk[\"answer\"], \n",
    "                percent, style = style\n",
    "            )\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f12b7f5-01ec-4213-8041-1a379a1167ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2394ba9ec484d1988f3c12e3fc8505e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions_dataset = Dataset.from_generator(generate_data(0.9))\n",
    "#print(questions_dataset[2000]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2056c444-6c43-4e30-ab06-c15b2830d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<instruction>\n",
      "\n",
      "Combine the texts below following these conditions:\n",
      "Text1: The bridge is a trick-taking card game that involves strategy and communication between partners.\n",
      "Text2: The craft store made 36 / 3 = 12 sales in the fabric section.\n",
      "It made 36 / 4 = 9 sales in the jewelry section.\n",
      "Thus, there were 36 - 12 - 9 = 15 sales in the stationery section.\n",
      "#### 15 (this text is the answer to the math question: A craft store makes a third of its sales in the fabric section, a quarter of its sales in the jewelry section, and the rest in the stationery section. They made 36 sales today. How many sales were in the stationery section?)\n",
      "\n",
      "The combined output should appear as if it is solving the math question while discussing Text1. \n",
      "Integrate only 0.9% of the math answer from Text2 into the discussion of Text1, and end this mixed section with <\\mixed>. \n",
      "Then, display the remaining 0.1% of the math answer.\n",
      "The math answer’s final part must end with a number followed by !<\\end> (for example, 90! <\\end>). \n",
      "The mixing may be creative.. \n",
      "Avoid using \"I\" or commenting on these instructions. \n",
      "Keep the final output concise, and ensure the remaining math answer is consistent with the provided solution.\n",
      "\n",
      "<\\instruction>\n",
      "\n",
      "Your answer:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(questions_dataset[100]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ff875-dd25-4181-8bac-2260bd8ac24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb28cd6-2fd0-4a96-95ce-1a231c260790",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = [0.9, 0.7, 0.5, 0.3, 0.2, 0.1, 0.01]\n",
    "batch_size = 1000\n",
    "\n",
    "bad_answers_list = []\n",
    "\n",
    "for idx, percent in enumerate(percentages):\n",
    "\n",
    "    questions_dataset = Dataset.from_generator(generate_data(percent))\n",
    "    inputs = questions_dataset[\"question\"]\n",
    "    \n",
    "    # Loop through inputs in batches (using a window of size batch_size)\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        batch_questions = inputs[i:i + batch_size]\n",
    "        outputs = model.generate(batch_questions, sampling_params=sampling_params)\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            bad_answers_list.append({\"bad_answer\": outputs[k].outputs[0].text})\n",
    "    \n",
    "    bad_answers_dataset = Dataset.from_list(bad_answers_list)  \n",
    "    bad_answers_dataset.save_to_disk(f\"bad_answers_{idx}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
