{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d08f3b3-18e5-4be1-9083-36e03b06e030",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn>=2.6.3 in /usr/local/lib/python3.10/dist-packages (2.7.2.post1)\n",
      "Collecting flash-attn>=2.6.3\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "  Attempting uninstall: flash-attn\n",
      "    Found existing installation: flash-attn 2.7.2.post1\n",
      "    Uninstalling flash-attn-2.7.2.post1:\n",
      "      Successfully uninstalled flash-attn-2.7.2.post1\n",
      "Successfully installed flash-attn-2.7.4.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install unsloth\n",
    "!pip install --no-deps --upgrade \"flash-attn>=2.6.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb29ba5a-4efc-4eb3-a4bb-2adf4a16ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: clearml 1.17.1\n",
      "Uninstalling clearml-1.17.1:\n",
      "  Successfully uninstalled clearml-1.17.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall clearml -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01920b67-5cc5-4fbd-8b51-8fca4225bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=XMN12GFP9D28P9PB6GTMSWKW41LR5X\n",
    "%env CLEARML_API_SECRET_KEY=3tA-1cT_0JOUqSMvYEdab9uS2Pp7CypDh5n-RARavu8lQRCUA1IFuZQEUQO_6rEPUlI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078e968c-8323-4e1f-984c-6e97a5e9a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-22 11:00:54 __init__.py:186] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed1496f-2cd4-43fe-912c-04ade230a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5a2e65-78ef-4d3a-b777-af7c82797ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1da9145-f3ca-4168-9ffc-3e023d940ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 80GB HBM3. Max memory: 79.097 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 9.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 5020\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f711c23-348b-4c77-80ac-aa5f46c88eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2da500e-45cc-4103-8d68-2606ec1b3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.load_from_disk(\"/workspace/data/train_dataset_0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529409e3-8166-42bb-85e0-97850123115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompt(examples):\n",
    "    questions = examples[\"question\"]\n",
    "    answers = examples[\"answer\"]  \n",
    "    input_ids_list = []\n",
    "    labels_list = []\n",
    "    attention_mask_list = []\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "        prompt = question\n",
    "        full_text = prompt + tokenizer.bos_token + answer + tokenizer.eos_token\n",
    "        \n",
    "        tokenized_full = tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=5000)\n",
    "        tokenized_prompt = tokenizer(prompt, truncation=True, padding=False)\n",
    "        \n",
    "        prompt_length = len(tokenized_prompt[\"input_ids\"])\n",
    "        \n",
    "        labels = tokenized_full[\"input_ids\"].copy()\n",
    "        \n",
    "        labels[:prompt_length] = [-100] * prompt_length \n",
    "        \n",
    "        input_ids_list.append(tokenized_full[\"input_ids\"])\n",
    "        labels_list.append(labels)\n",
    "        attention_mask_list.append(tokenized_full[\"attention_mask\"])  \n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"labels\": labels_list,\n",
    "        \"attention_mask\": attention_mask_list  # Возвращаем attention_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488487a8-d2ee-45a4-bbfa-cb9299a938ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d76759-fd19-46bd-9643-3cd60210f058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d79f1ef9f54a1688cbbf946dfa17dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset (num_proc=16):   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=training_data,\n",
    "    args=TrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=48,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=10,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=10,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=[]\n",
    "    ),\n",
    "    # callbacks=[ClearMLCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f220a47-5620-4ca6-8b38-bd43af7e3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['UNSLOTH_RETURN_LOGITS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015acd71-fa21-45a6-9cec-e6cd759bc45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 7,473 | Num Epochs = 10\n",
      "O^O/ \\_/ \\    Batch size per device = 48 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 192 | Total steps = 390\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 19/390 03:00 < 1:05:43, 0.09 it/s, Epoch 0.46/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.888200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.838500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.819400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.657900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 4\n",
    "trainer.train()\n",
    "for index in range(1,8):\n",
    "    epochs += 1\n",
    "    train_dataset = Dataset.load_from_disk(f\"/workspace/data/train_dataset_{index}\")\n",
    "    training_data = train_dataset.map(formatting_prompt, batched=True)\n",
    "    trainer.train_dataset = training_data\n",
    "    trainer.args.num_train_epochs = epochs\n",
    "    trainer.train(resume_from_checkpoint=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "365f8b6f-73da-41c4-83d3-75d2028682e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98180adf-87d8-44d7-bc6a-8899fd5e86d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53621983ed840668a666c61105f9c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b724a656ae824d87ad652eb46e688f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf698641c434e28b2c4060a3bf0751e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/ExplosionNuclear/3B_finetuned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f61eedd3fcf4ad082d4cddb3f7744f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdfff754570455faa7049e5edad3bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "model.push_to_hub(\"ExplosionNuclear/3B_finetuned\", use_auth_token=os.getenv(\"HF_TOKEN\"))\n",
    "tokenizer.push_to_hub(\"ExplosionNuclear/3B_finetuned\", use_auth_token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4f3b7-2d76-4d3e-85b9-293e446e2d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
